{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84eb8e47-7349-4a20-97fe-0cda2383f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "import chromadb\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e540f94a-9be6-4804-bb1c-5b6613e8a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_BASE\"] = \"your_api_base\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6b5f5-f114-4941-a0f4-dc214541ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder_path = \"your_pdf_folder_path\"\n",
    "documents = []\n",
    "for file in os.listdir(pdf_folder_path):\n",
    "    if file.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(pdf_folder_path, file)\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents.extend(loader.load())\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "chunked_documents = text_splitter.split_documents(documents)\n",
    "client = chromadb.Client()\n",
    "if client.list_collections():\n",
    "    consent_collection = client.create_collection(\"mentor_collection\")\n",
    "else:\n",
    "    print(\"Collection already exists\")\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=chunked_documents,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=\"./chroma_store\"\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e277f6",
   "metadata": {},
   "outputs": [],
   "source": [
    " #\"the question. The question is regarding the ability of the mentor to research\"\n",
    " #   \"specific field.\"\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name=model_name)\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks.\"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. The question is regarding the ability of the mentor to research\"\n",
    "    \"specific field.\"\n",
    "    \"You response should contain mentor_ID like '746', '518',you can get the id from content source\"\n",
    "    \"If you don't know the answer, say that you don't know\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    ")\n",
    "\n",
    "#question_answer_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"recommend an engineering mentor\")\n",
    "#rag_chain = create_retrieval_chain(retriever, question_answer_chain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f10878ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build a CSV retriever\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "csv_loader = CSVLoader(file_path='your_csv_file_path')\n",
    "documents = csv_loader.load()\n",
    "embeddings=OpenAIEmbeddings()\n",
    "\n",
    "csv_directory = './csv_db'\n",
    "csv_store = Chroma.from_documents(documents, embeddings, csv_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过人工链接将上一个链的信息传递到新的链\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name=model_name)\n",
    "csv_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks.\"\n",
    "    \"Based on the human input, you can get the research mentor ID\"\n",
    "    \"Use the following pieces of retrieved context to present the mentor ID's feedback and available time.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\")\n",
    "\n",
    "csv_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", csv_system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    ")\n",
    "\n",
    "csv_retriever = csv_store.as_retriever()\n",
    "\n",
    "csv_chain = (\n",
    "    {\"context\": csv_retriever, \"input\": RunnablePassthrough()}\n",
    "    | csv_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "csv_chain.invoke(\"I recommend mentor with ID 518, Hu, who has experience in mentoring undergraduate students in the field of Mechanical and Aerospace Engineering with a specialization in MEMS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55a65534",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = chain | csv_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain.invoke(\"recommend a CS mentor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6162c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6def3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436cf461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
